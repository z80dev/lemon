defmodule Ai.Models.OpenRouter do
  @moduledoc """
  Model definitions for the OpenRouter provider.

  This module is auto-extracted from `Ai.Models` as part of the
  per-provider decomposition (Debt Phase 5, M2).
  """

  alias Ai.Types.{Model, ModelCost}

  @models %{
    "ai21/jamba-large-1.7" => %Model{
      id: "ai21/jamba-large-1.7",
      name: "AI21: Jamba Large 1.7",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 2.0, output: 8.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 256_000,
      max_tokens: 4_096
    },
    "alibaba/tongyi-deepresearch-30b-a3b" => %Model{
      id: "alibaba/tongyi-deepresearch-30b-a3b",
      name: "Tongyi DeepResearch 30B A3B",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.09,
        output: 0.44999999999999996,
        cache_read: 0.09,
        cache_write: 0.0
      },
      context_window: 131_072,
      max_tokens: 131_072
    },
    "allenai/olmo-3.1-32b-instruct" => %Model{
      id: "allenai/olmo-3.1-32b-instruct",
      name: "AllenAI: Olmo 3.1 32B Instruct",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.19999999999999998,
        output: 0.6,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 65_536,
      max_tokens: 4_096
    },
    "amazon/nova-2-lite-v1" => %Model{
      id: "amazon/nova-2-lite-v1",
      name: "Amazon: Nova 2 Lite",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 0.3, output: 2.5, cache_read: 0.0, cache_write: 0.0},
      context_window: 1_000_000,
      max_tokens: 65_535
    },
    "amazon/nova-lite-v1" => %Model{
      id: "amazon/nova-lite-v1",
      name: "Amazon: Nova Lite 1.0",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 0.06, output: 0.24, cache_read: 0.0, cache_write: 0.0},
      context_window: 300_000,
      max_tokens: 5_120
    },
    "amazon/nova-micro-v1" => %Model{
      id: "amazon/nova-micro-v1",
      name: "Amazon: Nova Micro 1.0",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.035, output: 0.14, cache_read: 0.0, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 5_120
    },
    "amazon/nova-premier-v1" => %Model{
      id: "amazon/nova-premier-v1",
      name: "Amazon: Nova Premier 1.0",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 2.5, output: 12.5, cache_read: 0.625, cache_write: 0.0},
      context_window: 1_000_000,
      max_tokens: 32_000
    },
    "amazon/nova-pro-v1" => %Model{
      id: "amazon/nova-pro-v1",
      name: "Amazon: Nova Pro 1.0",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.7999999999999999,
        output: 3.1999999999999997,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 300_000,
      max_tokens: 5_120
    },
    "anthropic/claude-3-haiku" => %Model{
      id: "anthropic/claude-3-haiku",
      name: "Anthropic: Claude 3 Haiku",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 0.25, output: 1.25, cache_read: 0.03, cache_write: 0.3},
      context_window: 200_000,
      max_tokens: 4_096
    },
    "anthropic/claude-3.5-haiku" => %Model{
      id: "anthropic/claude-3.5-haiku",
      name: "Anthropic: Claude 3.5 Haiku",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.7999999999999999,
        output: 4.0,
        cache_read: 0.08,
        cache_write: 1.0
      },
      context_window: 200_000,
      max_tokens: 8_192
    },
    "anthropic/claude-3.5-sonnet" => %Model{
      id: "anthropic/claude-3.5-sonnet",
      name: "Anthropic: Claude 3.5 Sonnet",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 6.0, output: 30.0, cache_read: 0.6, cache_write: 7.5},
      context_window: 200_000,
      max_tokens: 8_192
    },
    "anthropic/claude-3.7-sonnet" => %Model{
      id: "anthropic/claude-3.7-sonnet",
      name: "Anthropic: Claude 3.7 Sonnet",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 3.0, output: 15.0, cache_read: 0.3, cache_write: 3.75},
      context_window: 200_000,
      max_tokens: 64_000
    },
    "anthropic/claude-3.7-sonnet:thinking" => %Model{
      id: "anthropic/claude-3.7-sonnet:thinking",
      name: "Anthropic: Claude 3.7 Sonnet (thinking)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 3.0, output: 15.0, cache_read: 0.3, cache_write: 3.75},
      context_window: 200_000,
      max_tokens: 64_000
    },
    "anthropic/claude-haiku-4.5" => %Model{
      id: "anthropic/claude-haiku-4.5",
      name: "Anthropic: Claude Haiku 4.5",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{
        input: 1.0,
        output: 5.0,
        cache_read: 0.09999999999999999,
        cache_write: 1.25
      },
      context_window: 200_000,
      max_tokens: 64_000
    },
    "anthropic/claude-opus-4" => %Model{
      id: "anthropic/claude-opus-4",
      name: "Anthropic: Claude Opus 4",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 15.0, output: 75.0, cache_read: 1.5, cache_write: 18.75},
      context_window: 200_000,
      max_tokens: 32_000
    },
    "anthropic/claude-opus-4.1" => %Model{
      id: "anthropic/claude-opus-4.1",
      name: "Anthropic: Claude Opus 4.1",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 15.0, output: 75.0, cache_read: 1.5, cache_write: 18.75},
      context_window: 200_000,
      max_tokens: 32_000
    },
    "anthropic/claude-opus-4.5" => %Model{
      id: "anthropic/claude-opus-4.5",
      name: "Anthropic: Claude Opus 4.5",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 5.0, output: 25.0, cache_read: 0.5, cache_write: 6.25},
      context_window: 200_000,
      max_tokens: 64_000
    },
    "anthropic/claude-opus-4.6" => %Model{
      id: "anthropic/claude-opus-4.6",
      name: "Anthropic: Claude Opus 4.6",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 5.0, output: 25.0, cache_read: 0.5, cache_write: 6.25},
      context_window: 1_000_000,
      max_tokens: 128_000
    },
    "anthropic/claude-sonnet-4" => %Model{
      id: "anthropic/claude-sonnet-4",
      name: "Anthropic: Claude Sonnet 4",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 3.0, output: 15.0, cache_read: 0.3, cache_write: 3.75},
      context_window: 1_000_000,
      max_tokens: 64_000
    },
    "anthropic/claude-sonnet-4.5" => %Model{
      id: "anthropic/claude-sonnet-4.5",
      name: "Anthropic: Claude Sonnet 4.5",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 3.0, output: 15.0, cache_read: 0.3, cache_write: 3.75},
      context_window: 1_000_000,
      max_tokens: 64_000
    },
    "anthropic/claude-sonnet-4.6" => %Model{
      id: "anthropic/claude-sonnet-4.6",
      name: "Anthropic: Claude Sonnet 4.6",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 3.0, output: 15.0, cache_read: 0.3, cache_write: 3.75},
      context_window: 1_000_000,
      max_tokens: 128_000
    },
    "arcee-ai/trinity-large-preview:free" => %Model{
      id: "arcee-ai/trinity-large-preview:free",
      name: "Arcee AI: Trinity Large Preview (free)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_000,
      max_tokens: 4_096
    },
    "arcee-ai/trinity-mini" => %Model{
      id: "arcee-ai/trinity-mini",
      name: "Arcee AI: Trinity Mini",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.045, output: 0.15, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 131_072
    },
    "arcee-ai/trinity-mini:free" => %Model{
      id: "arcee-ai/trinity-mini:free",
      name: "Arcee AI: Trinity Mini (free)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 4_096
    },
    "arcee-ai/virtuoso-large" => %Model{
      id: "arcee-ai/virtuoso-large",
      name: "Arcee AI: Virtuoso Large",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.75, output: 1.2, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 64_000
    },
    "auto" => %Model{
      id: "auto",
      name: "Auto",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 2_000_000,
      max_tokens: 30_000
    },
    "baidu/ernie-4.5-21b-a3b" => %Model{
      id: "baidu/ernie-4.5-21b-a3b",
      name: "Baidu: ERNIE 4.5 21B A3B",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.07, output: 0.28, cache_read: 0.0, cache_write: 0.0},
      context_window: 120_000,
      max_tokens: 8_000
    },
    "baidu/ernie-4.5-vl-28b-a3b" => %Model{
      id: "baidu/ernie-4.5-vl-28b-a3b",
      name: "Baidu: ERNIE 4.5 VL 28B A3B",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 0.14, output: 0.56, cache_read: 0.0, cache_write: 0.0},
      context_window: 30_000,
      max_tokens: 8_000
    },
    "bytedance-seed/seed-1.6" => %Model{
      id: "bytedance-seed/seed-1.6",
      name: "ByteDance Seed: Seed 1.6",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 0.25, output: 2.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 262_144,
      max_tokens: 32_768
    },
    "bytedance-seed/seed-1.6-flash" => %Model{
      id: "bytedance-seed/seed-1.6-flash",
      name: "ByteDance Seed: Seed 1.6 Flash",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 0.075, output: 0.3, cache_read: 0.0, cache_write: 0.0},
      context_window: 262_144,
      max_tokens: 32_768
    },
    "cohere/command-r-08-2024" => %Model{
      id: "cohere/command-r-08-2024",
      name: "Cohere: Command R (08-2024)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.15, output: 0.6, cache_read: 0.0, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 4_000
    },
    "cohere/command-r-plus-08-2024" => %Model{
      id: "cohere/command-r-plus-08-2024",
      name: "Cohere: Command R+ (08-2024)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 2.5, output: 10.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 4_000
    },
    "deepseek/deepseek-chat" => %Model{
      id: "deepseek/deepseek-chat",
      name: "DeepSeek: DeepSeek V3",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.32,
        output: 0.8899999999999999,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 163_840,
      max_tokens: 163_840
    },
    "deepseek/deepseek-chat-v3-0324" => %Model{
      id: "deepseek/deepseek-chat-v3-0324",
      name: "DeepSeek: DeepSeek V3 0324",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.19, output: 0.87, cache_read: 0.095, cache_write: 0.0},
      context_window: 163_840,
      max_tokens: 65_536
    },
    "deepseek/deepseek-chat-v3.1" => %Model{
      id: "deepseek/deepseek-chat-v3.1",
      name: "DeepSeek: DeepSeek V3.1",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.15, output: 0.75, cache_read: 0.0, cache_write: 0.0},
      context_window: 32_768,
      max_tokens: 7_168
    },
    "deepseek/deepseek-r1" => %Model{
      id: "deepseek/deepseek-r1",
      name: "DeepSeek: R1",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.7, output: 2.5, cache_read: 0.0, cache_write: 0.0},
      context_window: 64_000,
      max_tokens: 16_000
    },
    "deepseek/deepseek-r1-0528" => %Model{
      id: "deepseek/deepseek-r1-0528",
      name: "DeepSeek: R1 0528",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.39999999999999997,
        output: 1.75,
        cache_read: 0.19999999999999998,
        cache_write: 0.0
      },
      context_window: 163_840,
      max_tokens: 65_536
    },
    "deepseek/deepseek-v3.1-terminus" => %Model{
      id: "deepseek/deepseek-v3.1-terminus",
      name: "DeepSeek: DeepSeek V3.1 Terminus",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.21,
        output: 0.7899999999999999,
        cache_read: 0.1300000002,
        cache_write: 0.0
      },
      context_window: 163_840,
      max_tokens: 4_096
    },
    "deepseek/deepseek-v3.1-terminus:exacto" => %Model{
      id: "deepseek/deepseek-v3.1-terminus:exacto",
      name: "DeepSeek: DeepSeek V3.1 Terminus (exacto)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.21,
        output: 0.7899999999999999,
        cache_read: 0.16799999999999998,
        cache_write: 0.0
      },
      context_window: 163_840,
      max_tokens: 4_096
    },
    "deepseek/deepseek-v3.2" => %Model{
      id: "deepseek/deepseek-v3.2",
      name: "DeepSeek: DeepSeek V3.2",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.26, output: 0.38, cache_read: 0.13, cache_write: 0.0},
      context_window: 163_840,
      max_tokens: 4_096
    },
    "deepseek/deepseek-v3.2-exp" => %Model{
      id: "deepseek/deepseek-v3.2-exp",
      name: "DeepSeek: DeepSeek V3.2 Exp",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.27, output: 0.41, cache_read: 0.0, cache_write: 0.0},
      context_window: 163_840,
      max_tokens: 65_536
    },
    "google/gemini-2.0-flash-001" => %Model{
      id: "google/gemini-2.0-flash-001",
      name: "Google: Gemini 2.0 Flash",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.09999999999999999,
        output: 0.39999999999999997,
        cache_read: 0.024999999999999998,
        cache_write: 0.08333333333333334
      },
      context_window: 1_048_576,
      max_tokens: 8_192
    },
    "google/gemini-2.0-flash-lite-001" => %Model{
      id: "google/gemini-2.0-flash-lite-001",
      name: "Google: Gemini 2.0 Flash Lite",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 0.075, output: 0.3, cache_read: 0.0, cache_write: 0.0},
      context_window: 1_048_576,
      max_tokens: 8_192
    },
    "google/gemini-2.5-flash" => %Model{
      id: "google/gemini-2.5-flash",
      name: "Google: Gemini 2.5 Flash",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.3,
        output: 2.5,
        cache_read: 0.03,
        cache_write: 0.08333333333333334
      },
      context_window: 1_048_576,
      max_tokens: 65_535
    },
    "google/gemini-2.5-flash-lite" => %Model{
      id: "google/gemini-2.5-flash-lite",
      name: "Google: Gemini 2.5 Flash Lite",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.09999999999999999,
        output: 0.39999999999999997,
        cache_read: 0.01,
        cache_write: 0.08333333333333334
      },
      context_window: 1_048_576,
      max_tokens: 65_535
    },
    "google/gemini-2.5-flash-lite-preview-09-2025" => %Model{
      id: "google/gemini-2.5-flash-lite-preview-09-2025",
      name: "Google: Gemini 2.5 Flash Lite Preview 09-2025",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.09999999999999999,
        output: 0.39999999999999997,
        cache_read: 0.01,
        cache_write: 0.08333333333333334
      },
      context_window: 1_048_576,
      max_tokens: 65_535
    },
    "google/gemini-2.5-pro" => %Model{
      id: "google/gemini-2.5-pro",
      name: "Google: Gemini 2.5 Pro",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 1.25, output: 10.0, cache_read: 0.125, cache_write: 0.375},
      context_window: 1_048_576,
      max_tokens: 65_536
    },
    "google/gemini-2.5-pro-preview" => %Model{
      id: "google/gemini-2.5-pro-preview",
      name: "Google: Gemini 2.5 Pro Preview 06-05",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 1.25, output: 10.0, cache_read: 0.125, cache_write: 0.375},
      context_window: 1_048_576,
      max_tokens: 65_536
    },
    "google/gemini-2.5-pro-preview-05-06" => %Model{
      id: "google/gemini-2.5-pro-preview-05-06",
      name: "Google: Gemini 2.5 Pro Preview 05-06",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 1.25, output: 10.0, cache_read: 0.125, cache_write: 0.375},
      context_window: 1_048_576,
      max_tokens: 65_535
    },
    "google/gemini-3-flash-preview" => %Model{
      id: "google/gemini-3-flash-preview",
      name: "Google: Gemini 3 Flash Preview",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.5,
        output: 3.0,
        cache_read: 0.049999999999999996,
        cache_write: 0.08333333333333334
      },
      context_window: 1_048_576,
      max_tokens: 65_535
    },
    "google/gemini-3-pro-preview" => %Model{
      id: "google/gemini-3-pro-preview",
      name: "Google: Gemini 3 Pro Preview",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{
        input: 2.0,
        output: 12.0,
        cache_read: 0.19999999999999998,
        cache_write: 0.375
      },
      context_window: 1_048_576,
      max_tokens: 65_536
    },
    "google/gemini-3.1-pro-preview" => %Model{
      id: "google/gemini-3.1-pro-preview",
      name: "Google: Gemini 3.1 Pro Preview",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{
        input: 2.0,
        output: 12.0,
        cache_read: 0.19999999999999998,
        cache_write: 0.375
      },
      context_window: 1_048_576,
      max_tokens: 65_536
    },
    "google/gemma-3-27b-it" => %Model{
      id: "google/gemma-3-27b-it",
      name: "Google: Gemma 3 27B",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 0.04, output: 0.15, cache_read: 0.02, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 65_536
    },
    "google/gemma-3-27b-it:free" => %Model{
      id: "google/gemma-3-27b-it:free",
      name: "Google: Gemma 3 27B (free)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 8_192
    },
    "inception/mercury" => %Model{
      id: "inception/mercury",
      name: "Inception: Mercury",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.25, output: 1.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 16_384
    },
    "inception/mercury-coder" => %Model{
      id: "inception/mercury-coder",
      name: "Inception: Mercury Coder",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.25, output: 1.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 16_384
    },
    "kwaipilot/kat-coder-pro" => %Model{
      id: "kwaipilot/kat-coder-pro",
      name: "Kwaipilot: KAT-Coder-Pro V1",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.207, output: 0.828, cache_read: 0.0414, cache_write: 0.0},
      context_window: 256_000,
      max_tokens: 128_000
    },
    "meta-llama/llama-3-8b-instruct" => %Model{
      id: "meta-llama/llama-3-8b-instruct",
      name: "Meta: Llama 3 8B Instruct",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.03, output: 0.04, cache_read: 0.0, cache_write: 0.0},
      context_window: 8_192,
      max_tokens: 16_384
    },
    "meta-llama/llama-3.1-405b-instruct" => %Model{
      id: "meta-llama/llama-3.1-405b-instruct",
      name: "Meta: Llama 3.1 405B Instruct",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 4.0, output: 4.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_000,
      max_tokens: 4_096
    },
    "meta-llama/llama-3.1-70b-instruct" => %Model{
      id: "meta-llama/llama-3.1-70b-instruct",
      name: "Meta: Llama 3.1 70B Instruct",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.39999999999999997,
        output: 0.39999999999999997,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 131_072,
      max_tokens: 4_096
    },
    "meta-llama/llama-3.1-8b-instruct" => %Model{
      id: "meta-llama/llama-3.1-8b-instruct",
      name: "Meta: Llama 3.1 8B Instruct",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.02,
        output: 0.049999999999999996,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 16_384,
      max_tokens: 16_384
    },
    "meta-llama/llama-3.3-70b-instruct" => %Model{
      id: "meta-llama/llama-3.3-70b-instruct",
      name: "Meta: Llama 3.3 70B Instruct",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.09999999999999999,
        output: 0.32,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 131_072,
      max_tokens: 16_384
    },
    "meta-llama/llama-3.3-70b-instruct:free" => %Model{
      id: "meta-llama/llama-3.3-70b-instruct:free",
      name: "Meta: Llama 3.3 70B Instruct (free)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 128_000
    },
    "meta-llama/llama-4-maverick" => %Model{
      id: "meta-llama/llama-4-maverick",
      name: "Meta: Llama 4 Maverick",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 0.15, output: 0.6, cache_read: 0.0, cache_write: 0.0},
      context_window: 1_048_576,
      max_tokens: 16_384
    },
    "meta-llama/llama-4-scout" => %Model{
      id: "meta-llama/llama-4-scout",
      name: "Meta: Llama 4 Scout",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 0.08, output: 0.3, cache_read: 0.0, cache_write: 0.0},
      context_window: 327_680,
      max_tokens: 16_384
    },
    "minimax/minimax-m1" => %Model{
      id: "minimax/minimax-m1",
      name: "MiniMax: MiniMax M1",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.39999999999999997,
        output: 2.2,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 1_000_000,
      max_tokens: 40_000
    },
    "minimax/minimax-m2" => %Model{
      id: "minimax/minimax-m2",
      name: "MiniMax: MiniMax M2",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.255, output: 1.0, cache_read: 0.03, cache_write: 0.0},
      context_window: 196_608,
      max_tokens: 65_536
    },
    "minimax/minimax-m2.1" => %Model{
      id: "minimax/minimax-m2.1",
      name: "MiniMax: MiniMax M2.1",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.27, output: 0.95, cache_read: 0.0299999997, cache_write: 0.0},
      context_window: 196_608,
      max_tokens: 4_096
    },
    "minimax/minimax-m2.5" => %Model{
      id: "minimax/minimax-m2.5",
      name: "MiniMax: MiniMax M2.5",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.3, output: 1.1, cache_read: 0.15, cache_write: 0.0},
      context_window: 196_608,
      max_tokens: 65_536
    },
    "mistralai/codestral-2508" => %Model{
      id: "mistralai/codestral-2508",
      name: "Mistral: Codestral 2508",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.3,
        output: 0.8999999999999999,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 256_000,
      max_tokens: 4_096
    },
    "mistralai/devstral-2512" => %Model{
      id: "mistralai/devstral-2512",
      name: "Mistral: Devstral 2 2512",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.39999999999999997,
        output: 2.0,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 262_144,
      max_tokens: 4_096
    },
    "mistralai/devstral-medium" => %Model{
      id: "mistralai/devstral-medium",
      name: "Mistral: Devstral Medium",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.39999999999999997,
        output: 2.0,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 131_072,
      max_tokens: 4_096
    },
    "mistralai/devstral-small" => %Model{
      id: "mistralai/devstral-small",
      name: "Mistral: Devstral Small 1.1",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.09999999999999999,
        output: 0.3,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 131_072,
      max_tokens: 4_096
    },
    "mistralai/ministral-14b-2512" => %Model{
      id: "mistralai/ministral-14b-2512",
      name: "Mistral: Ministral 3 14B 2512",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.19999999999999998,
        output: 0.19999999999999998,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 262_144,
      max_tokens: 4_096
    },
    "mistralai/ministral-3b-2512" => %Model{
      id: "mistralai/ministral-3b-2512",
      name: "Mistral: Ministral 3 3B 2512",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.09999999999999999,
        output: 0.09999999999999999,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 131_072,
      max_tokens: 4_096
    },
    "mistralai/ministral-8b-2512" => %Model{
      id: "mistralai/ministral-8b-2512",
      name: "Mistral: Ministral 3 8B 2512",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 0.15, output: 0.15, cache_read: 0.0, cache_write: 0.0},
      context_window: 262_144,
      max_tokens: 4_096
    },
    "mistralai/mistral-large" => %Model{
      id: "mistralai/mistral-large",
      name: "Mistral Large",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 2.0, output: 6.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 4_096
    },
    "mistralai/mistral-large-2407" => %Model{
      id: "mistralai/mistral-large-2407",
      name: "Mistral Large 2407",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 2.0, output: 6.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 4_096
    },
    "mistralai/mistral-large-2411" => %Model{
      id: "mistralai/mistral-large-2411",
      name: "Mistral Large 2411",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 2.0, output: 6.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 4_096
    },
    "mistralai/mistral-large-2512" => %Model{
      id: "mistralai/mistral-large-2512",
      name: "Mistral: Mistral Large 3 2512",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 0.5, output: 1.5, cache_read: 0.0, cache_write: 0.0},
      context_window: 262_144,
      max_tokens: 4_096
    },
    "mistralai/mistral-medium-3" => %Model{
      id: "mistralai/mistral-medium-3",
      name: "Mistral: Mistral Medium 3",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.39999999999999997,
        output: 2.0,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 131_072,
      max_tokens: 4_096
    },
    "mistralai/mistral-medium-3.1" => %Model{
      id: "mistralai/mistral-medium-3.1",
      name: "Mistral: Mistral Medium 3.1",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.39999999999999997,
        output: 2.0,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 131_072,
      max_tokens: 4_096
    },
    "mistralai/mistral-nemo" => %Model{
      id: "mistralai/mistral-nemo",
      name: "Mistral: Mistral Nemo",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.02, output: 0.04, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 16_384
    },
    "mistralai/mistral-saba" => %Model{
      id: "mistralai/mistral-saba",
      name: "Mistral: Saba",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.19999999999999998,
        output: 0.6,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 32_768,
      max_tokens: 4_096
    },
    "mistralai/mistral-small-24b-instruct-2501" => %Model{
      id: "mistralai/mistral-small-24b-instruct-2501",
      name: "Mistral: Mistral Small 3",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.049999999999999996,
        output: 0.08,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 32_768,
      max_tokens: 16_384
    },
    "mistralai/mistral-small-3.1-24b-instruct:free" => %Model{
      id: "mistralai/mistral-small-3.1-24b-instruct:free",
      name: "Mistral: Mistral Small 3.1 24B (free)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 4_096
    },
    "mistralai/mistral-small-3.2-24b-instruct" => %Model{
      id: "mistralai/mistral-small-3.2-24b-instruct",
      name: "Mistral: Mistral Small 3.2 24B",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 0.06, output: 0.18, cache_read: 0.03, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 131_072
    },
    "mistralai/mistral-small-creative" => %Model{
      id: "mistralai/mistral-small-creative",
      name: "Mistral: Mistral Small Creative",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.09999999999999999,
        output: 0.3,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 32_768,
      max_tokens: 4_096
    },
    "mistralai/mixtral-8x22b-instruct" => %Model{
      id: "mistralai/mixtral-8x22b-instruct",
      name: "Mistral: Mixtral 8x22B Instruct",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 2.0, output: 6.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 65_536,
      max_tokens: 4_096
    },
    "mistralai/mixtral-8x7b-instruct" => %Model{
      id: "mistralai/mixtral-8x7b-instruct",
      name: "Mistral: Mixtral 8x7B Instruct",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.54, output: 0.54, cache_read: 0.0, cache_write: 0.0},
      context_window: 32_768,
      max_tokens: 16_384
    },
    "mistralai/pixtral-large-2411" => %Model{
      id: "mistralai/pixtral-large-2411",
      name: "Mistral: Pixtral Large 2411",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 2.0, output: 6.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 4_096
    },
    "mistralai/voxtral-small-24b-2507" => %Model{
      id: "mistralai/voxtral-small-24b-2507",
      name: "Mistral: Voxtral Small 24B 2507",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.09999999999999999,
        output: 0.3,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 32_000,
      max_tokens: 4_096
    },
    "moonshotai/kimi-k2" => %Model{
      id: "moonshotai/kimi-k2",
      name: "MoonshotAI: Kimi K2 0711",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.5, output: 2.4, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 4_096
    },
    "moonshotai/kimi-k2-0905" => %Model{
      id: "moonshotai/kimi-k2-0905",
      name: "MoonshotAI: Kimi K2 0905",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.39999999999999997,
        output: 2.0,
        cache_read: 0.15,
        cache_write: 0.0
      },
      context_window: 131_072,
      max_tokens: 4_096
    },
    "moonshotai/kimi-k2-0905:exacto" => %Model{
      id: "moonshotai/kimi-k2-0905:exacto",
      name: "MoonshotAI: Kimi K2 0905 (exacto)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.6, output: 2.5, cache_read: 0.0, cache_write: 0.0},
      context_window: 262_144,
      max_tokens: 4_096
    },
    "moonshotai/kimi-k2-thinking" => %Model{
      id: "moonshotai/kimi-k2-thinking",
      name: "MoonshotAI: Kimi K2 Thinking",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.47,
        output: 2.0,
        cache_read: 0.14100000000000001,
        cache_write: 0.0
      },
      context_window: 131_072,
      max_tokens: 4_096
    },
    "moonshotai/kimi-k2.5" => %Model{
      id: "moonshotai/kimi-k2.5",
      name: "MoonshotAI: Kimi K2.5",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.22999999999999998,
        output: 3.0,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 262_144,
      max_tokens: 262_144
    },
    "nex-agi/deepseek-v3.1-nex-n1" => %Model{
      id: "nex-agi/deepseek-v3.1-nex-n1",
      name: "Nex AGI: DeepSeek V3.1 Nex N1",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.27, output: 1.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 163_840
    },
    "nvidia/llama-3.1-nemotron-70b-instruct" => %Model{
      id: "nvidia/llama-3.1-nemotron-70b-instruct",
      name: "NVIDIA: Llama 3.1 Nemotron 70B Instruct",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 1.2, output: 1.2, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 16_384
    },
    "nvidia/llama-3.3-nemotron-super-49b-v1.5" => %Model{
      id: "nvidia/llama-3.3-nemotron-super-49b-v1.5",
      name: "NVIDIA: Llama 3.3 Nemotron Super 49B V1.5",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.09999999999999999,
        output: 0.39999999999999997,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 131_072,
      max_tokens: 4_096
    },
    "nvidia/nemotron-3-nano-30b-a3b" => %Model{
      id: "nvidia/nemotron-3-nano-30b-a3b",
      name: "NVIDIA: Nemotron 3 Nano 30B A3B",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.049999999999999996,
        output: 0.19999999999999998,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 262_144,
      max_tokens: 4_096
    },
    "nvidia/nemotron-3-nano-30b-a3b:free" => %Model{
      id: "nvidia/nemotron-3-nano-30b-a3b:free",
      name: "NVIDIA: Nemotron 3 Nano 30B A3B (free)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 256_000,
      max_tokens: 4_096
    },
    "nvidia/nemotron-nano-12b-v2-vl:free" => %Model{
      id: "nvidia/nemotron-nano-12b-v2-vl:free",
      name: "NVIDIA: Nemotron Nano 12B 2 VL (free)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 128_000
    },
    "nvidia/nemotron-nano-9b-v2" => %Model{
      id: "nvidia/nemotron-nano-9b-v2",
      name: "NVIDIA: Nemotron Nano 9B V2",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.04, output: 0.16, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 4_096
    },
    "nvidia/nemotron-nano-9b-v2:free" => %Model{
      id: "nvidia/nemotron-nano-9b-v2:free",
      name: "NVIDIA: Nemotron Nano 9B V2 (free)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 4_096
    },
    "openai/gpt-3.5-turbo" => %Model{
      id: "openai/gpt-3.5-turbo",
      name: "OpenAI: GPT-3.5 Turbo",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.5, output: 1.5, cache_read: 0.0, cache_write: 0.0},
      context_window: 16_385,
      max_tokens: 4_096
    },
    "openai/gpt-3.5-turbo-0613" => %Model{
      id: "openai/gpt-3.5-turbo-0613",
      name: "OpenAI: GPT-3.5 Turbo (older v0613)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 1.0, output: 2.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 4_095,
      max_tokens: 4_096
    },
    "openai/gpt-3.5-turbo-16k" => %Model{
      id: "openai/gpt-3.5-turbo-16k",
      name: "OpenAI: GPT-3.5 Turbo 16k",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 3.0, output: 4.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 16_385,
      max_tokens: 4_096
    },
    "openai/gpt-4" => %Model{
      id: "openai/gpt-4",
      name: "OpenAI: GPT-4",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 30.0, output: 60.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 8_191,
      max_tokens: 4_096
    },
    "openai/gpt-4-0314" => %Model{
      id: "openai/gpt-4-0314",
      name: "OpenAI: GPT-4 (older v0314)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 30.0, output: 60.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 8_191,
      max_tokens: 4_096
    },
    "openai/gpt-4-1106-preview" => %Model{
      id: "openai/gpt-4-1106-preview",
      name: "OpenAI: GPT-4 Turbo (older v1106)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 10.0, output: 30.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 4_096
    },
    "openai/gpt-4-turbo" => %Model{
      id: "openai/gpt-4-turbo",
      name: "OpenAI: GPT-4 Turbo",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 10.0, output: 30.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 4_096
    },
    "openai/gpt-4-turbo-preview" => %Model{
      id: "openai/gpt-4-turbo-preview",
      name: "OpenAI: GPT-4 Turbo Preview",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 10.0, output: 30.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 4_096
    },
    "openai/gpt-4.1" => %Model{
      id: "openai/gpt-4.1",
      name: "OpenAI: GPT-4.1",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 2.0, output: 8.0, cache_read: 0.5, cache_write: 0.0},
      context_window: 1_047_576,
      max_tokens: 32_768
    },
    "openai/gpt-4.1-mini" => %Model{
      id: "openai/gpt-4.1-mini",
      name: "OpenAI: GPT-4.1 Mini",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.39999999999999997,
        output: 1.5999999999999999,
        cache_read: 0.09999999999999999,
        cache_write: 0.0
      },
      context_window: 1_047_576,
      max_tokens: 32_768
    },
    "openai/gpt-4.1-nano" => %Model{
      id: "openai/gpt-4.1-nano",
      name: "OpenAI: GPT-4.1 Nano",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.09999999999999999,
        output: 0.39999999999999997,
        cache_read: 0.024999999999999998,
        cache_write: 0.0
      },
      context_window: 1_047_576,
      max_tokens: 32_768
    },
    "openai/gpt-4o" => %Model{
      id: "openai/gpt-4o",
      name: "OpenAI: GPT-4o",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 2.5, output: 10.0, cache_read: 1.25, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 16_384
    },
    "openai/gpt-4o-2024-05-13" => %Model{
      id: "openai/gpt-4o-2024-05-13",
      name: "OpenAI: GPT-4o (2024-05-13)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 5.0, output: 15.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 4_096
    },
    "openai/gpt-4o-2024-08-06" => %Model{
      id: "openai/gpt-4o-2024-08-06",
      name: "OpenAI: GPT-4o (2024-08-06)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 2.5, output: 10.0, cache_read: 1.25, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 16_384
    },
    "openai/gpt-4o-2024-11-20" => %Model{
      id: "openai/gpt-4o-2024-11-20",
      name: "OpenAI: GPT-4o (2024-11-20)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 2.5, output: 10.0, cache_read: 1.25, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 16_384
    },
    "openai/gpt-4o-audio-preview" => %Model{
      id: "openai/gpt-4o-audio-preview",
      name: "OpenAI: GPT-4o Audio",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 2.5, output: 10.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 16_384
    },
    "openai/gpt-4o-mini" => %Model{
      id: "openai/gpt-4o-mini",
      name: "OpenAI: GPT-4o-mini",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 0.15, output: 0.6, cache_read: 0.075, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 16_384
    },
    "openai/gpt-4o-mini-2024-07-18" => %Model{
      id: "openai/gpt-4o-mini-2024-07-18",
      name: "OpenAI: GPT-4o-mini (2024-07-18)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 0.15, output: 0.6, cache_read: 0.075, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 16_384
    },
    "openai/gpt-4o:extended" => %Model{
      id: "openai/gpt-4o:extended",
      name: "OpenAI: GPT-4o (extended)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 6.0, output: 18.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 64_000
    },
    "openai/gpt-5" => %Model{
      id: "openai/gpt-5",
      name: "OpenAI: GPT-5",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 1.25, output: 10.0, cache_read: 0.125, cache_write: 0.0},
      context_window: 400_000,
      max_tokens: 128_000
    },
    "openai/gpt-5-codex" => %Model{
      id: "openai/gpt-5-codex",
      name: "OpenAI: GPT-5 Codex",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 1.25, output: 10.0, cache_read: 0.125, cache_write: 0.0},
      context_window: 400_000,
      max_tokens: 128_000
    },
    "openai/gpt-5-image" => %Model{
      id: "openai/gpt-5-image",
      name: "OpenAI: GPT-5 Image",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 10.0, output: 10.0, cache_read: 1.25, cache_write: 0.0},
      context_window: 400_000,
      max_tokens: 128_000
    },
    "openai/gpt-5-image-mini" => %Model{
      id: "openai/gpt-5-image-mini",
      name: "OpenAI: GPT-5 Image Mini",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 2.5, output: 2.0, cache_read: 0.25, cache_write: 0.0},
      context_window: 400_000,
      max_tokens: 128_000
    },
    "openai/gpt-5-mini" => %Model{
      id: "openai/gpt-5-mini",
      name: "OpenAI: GPT-5 Mini",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.25,
        output: 2.0,
        cache_read: 0.024999999999999998,
        cache_write: 0.0
      },
      context_window: 400_000,
      max_tokens: 128_000
    },
    "openai/gpt-5-nano" => %Model{
      id: "openai/gpt-5-nano",
      name: "OpenAI: GPT-5 Nano",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.049999999999999996,
        output: 0.39999999999999997,
        cache_read: 0.005,
        cache_write: 0.0
      },
      context_window: 400_000,
      max_tokens: 128_000
    },
    "openai/gpt-5-pro" => %Model{
      id: "openai/gpt-5-pro",
      name: "OpenAI: GPT-5 Pro",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 15.0, output: 120.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 400_000,
      max_tokens: 128_000
    },
    "openai/gpt-5.1" => %Model{
      id: "openai/gpt-5.1",
      name: "OpenAI: GPT-5.1",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 1.25, output: 10.0, cache_read: 0.125, cache_write: 0.0},
      context_window: 400_000,
      max_tokens: 128_000
    },
    "openai/gpt-5.1-chat" => %Model{
      id: "openai/gpt-5.1-chat",
      name: "OpenAI: GPT-5.1 Chat",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 1.25, output: 10.0, cache_read: 0.125, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 16_384
    },
    "openai/gpt-5.1-codex" => %Model{
      id: "openai/gpt-5.1-codex",
      name: "OpenAI: GPT-5.1-Codex",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 1.25, output: 10.0, cache_read: 0.125, cache_write: 0.0},
      context_window: 400_000,
      max_tokens: 128_000
    },
    "openai/gpt-5.1-codex-max" => %Model{
      id: "openai/gpt-5.1-codex-max",
      name: "OpenAI: GPT-5.1-Codex-Max",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 1.25, output: 10.0, cache_read: 0.125, cache_write: 0.0},
      context_window: 400_000,
      max_tokens: 128_000
    },
    "openai/gpt-5.1-codex-mini" => %Model{
      id: "openai/gpt-5.1-codex-mini",
      name: "OpenAI: GPT-5.1-Codex-Mini",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.25,
        output: 2.0,
        cache_read: 0.024999999999999998,
        cache_write: 0.0
      },
      context_window: 400_000,
      max_tokens: 100_000
    },
    "openai/gpt-5.2" => %Model{
      id: "openai/gpt-5.2",
      name: "OpenAI: GPT-5.2",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 1.75, output: 14.0, cache_read: 0.175, cache_write: 0.0},
      context_window: 400_000,
      max_tokens: 128_000
    },
    "openai/gpt-5.2-chat" => %Model{
      id: "openai/gpt-5.2-chat",
      name: "OpenAI: GPT-5.2 Chat",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 1.75, output: 14.0, cache_read: 0.175, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 16_384
    },
    "openai/gpt-5.2-codex" => %Model{
      id: "openai/gpt-5.2-codex",
      name: "OpenAI: GPT-5.2-Codex",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 1.75, output: 14.0, cache_read: 0.175, cache_write: 0.0},
      context_window: 400_000,
      max_tokens: 128_000
    },
    "openai/gpt-5.2-pro" => %Model{
      id: "openai/gpt-5.2-pro",
      name: "OpenAI: GPT-5.2 Pro",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 21.0, output: 168.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 400_000,
      max_tokens: 128_000
    },
    "openai/gpt-oss-120b" => %Model{
      id: "openai/gpt-oss-120b",
      name: "OpenAI: gpt-oss-120b",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.039, output: 0.19, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 4_096
    },
    "openai/gpt-oss-120b:exacto" => %Model{
      id: "openai/gpt-oss-120b:exacto",
      name: "OpenAI: gpt-oss-120b (exacto)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.039, output: 0.19, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 4_096
    },
    "openai/gpt-oss-120b:free" => %Model{
      id: "openai/gpt-oss-120b:free",
      name: "OpenAI: gpt-oss-120b (free)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 131_072
    },
    "openai/gpt-oss-20b" => %Model{
      id: "openai/gpt-oss-20b",
      name: "OpenAI: gpt-oss-20b",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.03, output: 0.14, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 4_096
    },
    "openai/gpt-oss-20b:free" => %Model{
      id: "openai/gpt-oss-20b:free",
      name: "OpenAI: gpt-oss-20b (free)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 131_072
    },
    "openai/gpt-oss-safeguard-20b" => %Model{
      id: "openai/gpt-oss-safeguard-20b",
      name: "OpenAI: gpt-oss-safeguard-20b",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.075, output: 0.3, cache_read: 0.037, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 65_536
    },
    "openai/o1" => %Model{
      id: "openai/o1",
      name: "OpenAI: o1",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 15.0, output: 60.0, cache_read: 7.5, cache_write: 0.0},
      context_window: 200_000,
      max_tokens: 100_000
    },
    "openai/o3" => %Model{
      id: "openai/o3",
      name: "OpenAI: o3",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 2.0, output: 8.0, cache_read: 0.5, cache_write: 0.0},
      context_window: 200_000,
      max_tokens: 100_000
    },
    "openai/o3-deep-research" => %Model{
      id: "openai/o3-deep-research",
      name: "OpenAI: o3 Deep Research",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 10.0, output: 40.0, cache_read: 2.5, cache_write: 0.0},
      context_window: 200_000,
      max_tokens: 100_000
    },
    "openai/o3-mini" => %Model{
      id: "openai/o3-mini",
      name: "OpenAI: o3 Mini",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 1.1, output: 4.4, cache_read: 0.55, cache_write: 0.0},
      context_window: 200_000,
      max_tokens: 100_000
    },
    "openai/o3-mini-high" => %Model{
      id: "openai/o3-mini-high",
      name: "OpenAI: o3 Mini High",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 1.1, output: 4.4, cache_read: 0.55, cache_write: 0.0},
      context_window: 200_000,
      max_tokens: 100_000
    },
    "openai/o3-pro" => %Model{
      id: "openai/o3-pro",
      name: "OpenAI: o3 Pro",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 20.0, output: 80.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 200_000,
      max_tokens: 100_000
    },
    "openai/o4-mini" => %Model{
      id: "openai/o4-mini",
      name: "OpenAI: o4 Mini",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 1.1, output: 4.4, cache_read: 0.275, cache_write: 0.0},
      context_window: 200_000,
      max_tokens: 100_000
    },
    "openai/o4-mini-deep-research" => %Model{
      id: "openai/o4-mini-deep-research",
      name: "OpenAI: o4 Mini Deep Research",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 2.0, output: 8.0, cache_read: 0.5, cache_write: 0.0},
      context_window: 200_000,
      max_tokens: 100_000
    },
    "openai/o4-mini-high" => %Model{
      id: "openai/o4-mini-high",
      name: "OpenAI: o4 Mini High",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 1.1, output: 4.4, cache_read: 0.275, cache_write: 0.0},
      context_window: 200_000,
      max_tokens: 100_000
    },
    "openrouter/auto" => %Model{
      id: "openrouter/auto",
      name: "Auto Router",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 2_000_000,
      max_tokens: 4_096
    },
    "openrouter/free" => %Model{
      id: "openrouter/free",
      name: "Free Models Router",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 200_000,
      max_tokens: 4_096
    },
    "prime-intellect/intellect-3" => %Model{
      id: "prime-intellect/intellect-3",
      name: "Prime Intellect: INTELLECT-3",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.19999999999999998,
        output: 1.1,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 131_072,
      max_tokens: 131_072
    },
    "qwen/qwen-2.5-72b-instruct" => %Model{
      id: "qwen/qwen-2.5-72b-instruct",
      name: "Qwen2.5 72B Instruct",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.12, output: 0.39, cache_read: 0.0, cache_write: 0.0},
      context_window: 32_768,
      max_tokens: 16_384
    },
    "qwen/qwen-2.5-7b-instruct" => %Model{
      id: "qwen/qwen-2.5-7b-instruct",
      name: "Qwen: Qwen2.5 7B Instruct",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.04,
        output: 0.09999999999999999,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 32_768,
      max_tokens: 4_096
    },
    "qwen/qwen-max" => %Model{
      id: "qwen/qwen-max",
      name: "Qwen: Qwen-Max ",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 1.5999999999999999,
        output: 6.3999999999999995,
        cache_read: 0.32,
        cache_write: 0.0
      },
      context_window: 32_768,
      max_tokens: 8_192
    },
    "qwen/qwen-plus" => %Model{
      id: "qwen/qwen-plus",
      name: "Qwen: Qwen-Plus",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.39999999999999997,
        output: 1.2,
        cache_read: 0.08,
        cache_write: 0.0
      },
      context_window: 1_000_000,
      max_tokens: 32_768
    },
    "qwen/qwen-plus-2025-07-28" => %Model{
      id: "qwen/qwen-plus-2025-07-28",
      name: "Qwen: Qwen Plus 0728",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.39999999999999997,
        output: 1.2,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 1_000_000,
      max_tokens: 32_768
    },
    "qwen/qwen-plus-2025-07-28:thinking" => %Model{
      id: "qwen/qwen-plus-2025-07-28:thinking",
      name: "Qwen: Qwen Plus 0728 (thinking)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.39999999999999997,
        output: 1.2,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 1_000_000,
      max_tokens: 32_768
    },
    "qwen/qwen-turbo" => %Model{
      id: "qwen/qwen-turbo",
      name: "Qwen: Qwen-Turbo",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.049999999999999996,
        output: 0.19999999999999998,
        cache_read: 0.01,
        cache_write: 0.0
      },
      context_window: 131_072,
      max_tokens: 8_192
    },
    "qwen/qwen-vl-max" => %Model{
      id: "qwen/qwen-vl-max",
      name: "Qwen: Qwen VL Max",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.7999999999999999,
        output: 3.1999999999999997,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 131_072,
      max_tokens: 32_768
    },
    "qwen/qwen3-14b" => %Model{
      id: "qwen/qwen3-14b",
      name: "Qwen: Qwen3 14B",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.06, output: 0.24, cache_read: 0.0, cache_write: 0.0},
      context_window: 40_960,
      max_tokens: 40_960
    },
    "qwen/qwen3-235b-a22b" => %Model{
      id: "qwen/qwen3-235b-a22b",
      name: "Qwen: Qwen3 235B A22B",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.45499999999999996,
        output: 1.8199999999999998,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 131_072,
      max_tokens: 8_192
    },
    "qwen/qwen3-235b-a22b-2507" => %Model{
      id: "qwen/qwen3-235b-a22b-2507",
      name: "Qwen: Qwen3 235B A22B Instruct 2507",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.071,
        output: 0.09999999999999999,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 262_144,
      max_tokens: 4_096
    },
    "qwen/qwen3-235b-a22b-thinking-2507" => %Model{
      id: "qwen/qwen3-235b-a22b-thinking-2507",
      name: "Qwen: Qwen3 235B A22B Thinking 2507",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 4_096
    },
    "qwen/qwen3-30b-a3b" => %Model{
      id: "qwen/qwen3-30b-a3b",
      name: "Qwen: Qwen3 30B A3B",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.08, output: 0.28, cache_read: 0.0, cache_write: 0.0},
      context_window: 40_960,
      max_tokens: 40_960
    },
    "qwen/qwen3-30b-a3b-instruct-2507" => %Model{
      id: "qwen/qwen3-30b-a3b-instruct-2507",
      name: "Qwen: Qwen3 30B A3B Instruct 2507",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.09, output: 0.3, cache_read: 0.0, cache_write: 0.0},
      context_window: 262_144,
      max_tokens: 262_144
    },
    "qwen/qwen3-30b-a3b-thinking-2507" => %Model{
      id: "qwen/qwen3-30b-a3b-thinking-2507",
      name: "Qwen: Qwen3 30B A3B Thinking 2507",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.051,
        output: 0.33999999999999997,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 32_768,
      max_tokens: 4_096
    },
    "qwen/qwen3-32b" => %Model{
      id: "qwen/qwen3-32b",
      name: "Qwen: Qwen3 32B",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.08, output: 0.24, cache_read: 0.04, cache_write: 0.0},
      context_window: 40_960,
      max_tokens: 40_960
    },
    "qwen/qwen3-4b:free" => %Model{
      id: "qwen/qwen3-4b:free",
      name: "Qwen: Qwen3 4B (free)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 40_960,
      max_tokens: 4_096
    },
    "qwen/qwen3-8b" => %Model{
      id: "qwen/qwen3-8b",
      name: "Qwen: Qwen3 8B",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.049999999999999996,
        output: 0.39999999999999997,
        cache_read: 0.049999999999999996,
        cache_write: 0.0
      },
      context_window: 32_000,
      max_tokens: 8_192
    },
    "qwen/qwen3-coder" => %Model{
      id: "qwen/qwen3-coder",
      name: "Qwen: Qwen3 Coder 480B A35B",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.22, output: 1.0, cache_read: 0.022, cache_write: 0.0},
      context_window: 262_144,
      max_tokens: 4_096
    },
    "qwen/qwen3-coder-30b-a3b-instruct" => %Model{
      id: "qwen/qwen3-coder-30b-a3b-instruct",
      name: "Qwen: Qwen3 Coder 30B A3B Instruct",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.07, output: 0.27, cache_read: 0.0, cache_write: 0.0},
      context_window: 160_000,
      max_tokens: 32_768
    },
    "qwen/qwen3-coder-flash" => %Model{
      id: "qwen/qwen3-coder-flash",
      name: "Qwen: Qwen3 Coder Flash",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.3, output: 1.5, cache_read: 0.06, cache_write: 0.0},
      context_window: 1_000_000,
      max_tokens: 65_536
    },
    "qwen/qwen3-coder-next" => %Model{
      id: "qwen/qwen3-coder-next",
      name: "Qwen: Qwen3 Coder Next",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.12, output: 0.75, cache_read: 0.06, cache_write: 0.0},
      context_window: 262_144,
      max_tokens: 65_536
    },
    "qwen/qwen3-coder-plus" => %Model{
      id: "qwen/qwen3-coder-plus",
      name: "Qwen: Qwen3 Coder Plus",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 1.0,
        output: 5.0,
        cache_read: 0.19999999999999998,
        cache_write: 0.0
      },
      context_window: 1_000_000,
      max_tokens: 65_536
    },
    "qwen/qwen3-coder:exacto" => %Model{
      id: "qwen/qwen3-coder:exacto",
      name: "Qwen: Qwen3 Coder 480B A35B (exacto)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.22,
        output: 1.7999999999999998,
        cache_read: 0.022,
        cache_write: 0.0
      },
      context_window: 262_144,
      max_tokens: 65_536
    },
    "qwen/qwen3-coder:free" => %Model{
      id: "qwen/qwen3-coder:free",
      name: "Qwen: Qwen3 Coder 480B A35B (free)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 262_000,
      max_tokens: 262_000
    },
    "qwen/qwen3-max" => %Model{
      id: "qwen/qwen3-max",
      name: "Qwen: Qwen3 Max",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 1.2, output: 6.0, cache_read: 0.24, cache_write: 0.0},
      context_window: 262_144,
      max_tokens: 65_536
    },
    "qwen/qwen3-max-thinking" => %Model{
      id: "qwen/qwen3-max-thinking",
      name: "Qwen: Qwen3 Max Thinking",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 1.2, output: 6.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 262_144,
      max_tokens: 65_536
    },
    "qwen/qwen3-next-80b-a3b-instruct" => %Model{
      id: "qwen/qwen3-next-80b-a3b-instruct",
      name: "Qwen: Qwen3 Next 80B A3B Instruct",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.09, output: 1.1, cache_read: 0.0, cache_write: 0.0},
      context_window: 262_144,
      max_tokens: 4_096
    },
    "qwen/qwen3-next-80b-a3b-instruct:free" => %Model{
      id: "qwen/qwen3-next-80b-a3b-instruct:free",
      name: "Qwen: Qwen3 Next 80B A3B Instruct (free)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 262_144,
      max_tokens: 4_096
    },
    "qwen/qwen3-next-80b-a3b-thinking" => %Model{
      id: "qwen/qwen3-next-80b-a3b-thinking",
      name: "Qwen: Qwen3 Next 80B A3B Thinking",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.15, output: 1.2, cache_read: 0.0, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 4_096
    },
    "qwen/qwen3-vl-235b-a22b-instruct" => %Model{
      id: "qwen/qwen3-vl-235b-a22b-instruct",
      name: "Qwen: Qwen3 VL 235B A22B Instruct",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.19999999999999998,
        output: 0.88,
        cache_read: 0.11,
        cache_write: 0.0
      },
      context_window: 262_144,
      max_tokens: 4_096
    },
    "qwen/qwen3-vl-235b-a22b-thinking" => %Model{
      id: "qwen/qwen3-vl-235b-a22b-thinking",
      name: "Qwen: Qwen3 VL 235B A22B Thinking",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 32_768
    },
    "qwen/qwen3-vl-30b-a3b-instruct" => %Model{
      id: "qwen/qwen3-vl-30b-a3b-instruct",
      name: "Qwen: Qwen3 VL 30B A3B Instruct",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 0.13, output: 0.52, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 32_768
    },
    "qwen/qwen3-vl-30b-a3b-thinking" => %Model{
      id: "qwen/qwen3-vl-30b-a3b-thinking",
      name: "Qwen: Qwen3 VL 30B A3B Thinking",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 32_768
    },
    "qwen/qwen3-vl-32b-instruct" => %Model{
      id: "qwen/qwen3-vl-32b-instruct",
      name: "Qwen: Qwen3 VL 32B Instruct",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.10400000000000001,
        output: 0.41600000000000004,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 131_072,
      max_tokens: 32_768
    },
    "qwen/qwen3-vl-8b-instruct" => %Model{
      id: "qwen/qwen3-vl-8b-instruct",
      name: "Qwen: Qwen3 VL 8B Instruct",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text, :image],
      cost: %ModelCost{input: 0.08, output: 0.5, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 32_768
    },
    "qwen/qwen3-vl-8b-thinking" => %Model{
      id: "qwen/qwen3-vl-8b-thinking",
      name: "Qwen: Qwen3 VL 8B Thinking",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 0.117, output: 1.365, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 32_768
    },
    "qwen/qwen3.5-397b-a17b" => %Model{
      id: "qwen/qwen3.5-397b-a17b",
      name: "Qwen: Qwen3.5 397B A17B",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 0.15, output: 1.0, cache_read: 0.15, cache_write: 0.0},
      context_window: 262_144,
      max_tokens: 65_536
    },
    "qwen/qwen3.5-plus-02-15" => %Model{
      id: "qwen/qwen3.5-plus-02-15",
      name: "Qwen: Qwen3.5 Plus 2026-02-15",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.39999999999999997,
        output: 2.4,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 1_000_000,
      max_tokens: 65_536
    },
    "qwen/qwq-32b" => %Model{
      id: "qwen/qwq-32b",
      name: "Qwen: QwQ 32B",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.15,
        output: 0.39999999999999997,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 32_768,
      max_tokens: 32_768
    },
    "relace/relace-search" => %Model{
      id: "relace/relace-search",
      name: "Relace: Relace Search",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 1.0, output: 3.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 256_000,
      max_tokens: 128_000
    },
    "sao10k/l3-euryale-70b" => %Model{
      id: "sao10k/l3-euryale-70b",
      name: "Sao10k: Llama 3 Euryale 70B v2.1",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 1.48, output: 1.48, cache_read: 0.0, cache_write: 0.0},
      context_window: 8_192,
      max_tokens: 8_192
    },
    "sao10k/l3.1-euryale-70b" => %Model{
      id: "sao10k/l3.1-euryale-70b",
      name: "Sao10K: Llama 3.1 Euryale 70B v2.2",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 0.65, output: 0.75, cache_read: 0.0, cache_write: 0.0},
      context_window: 32_768,
      max_tokens: 32_768
    },
    "stepfun/step-3.5-flash" => %Model{
      id: "stepfun/step-3.5-flash",
      name: "StepFun: Step 3.5 Flash",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.09999999999999999,
        output: 0.3,
        cache_read: 0.02,
        cache_write: 0.0
      },
      context_window: 256_000,
      max_tokens: 256_000
    },
    "stepfun/step-3.5-flash:free" => %Model{
      id: "stepfun/step-3.5-flash:free",
      name: "StepFun: Step 3.5 Flash (free)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 256_000,
      max_tokens: 256_000
    },
    "thedrummer/rocinante-12b" => %Model{
      id: "thedrummer/rocinante-12b",
      name: "TheDrummer: Rocinante 12B",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.16999999999999998,
        output: 0.43,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 32_768,
      max_tokens: 32_768
    },
    "thedrummer/unslopnemo-12b" => %Model{
      id: "thedrummer/unslopnemo-12b",
      name: "TheDrummer: UnslopNemo 12B",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.39999999999999997,
        output: 0.39999999999999997,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 32_768,
      max_tokens: 32_768
    },
    "tngtech/deepseek-r1t2-chimera" => %Model{
      id: "tngtech/deepseek-r1t2-chimera",
      name: "TNG: DeepSeek R1T2 Chimera",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.25, output: 0.85, cache_read: 0.125, cache_write: 0.0},
      context_window: 163_840,
      max_tokens: 163_840
    },
    "upstage/solar-pro-3:free" => %Model{
      id: "upstage/solar-pro-3:free",
      name: "Upstage: Solar Pro 3 (free)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 128_000,
      max_tokens: 4_096
    },
    "x-ai/grok-3" => %Model{
      id: "x-ai/grok-3",
      name: "xAI: Grok 3",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 3.0, output: 15.0, cache_read: 0.75, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 4_096
    },
    "x-ai/grok-3-beta" => %Model{
      id: "x-ai/grok-3-beta",
      name: "xAI: Grok 3 Beta",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{input: 3.0, output: 15.0, cache_read: 0.75, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 4_096
    },
    "x-ai/grok-3-mini" => %Model{
      id: "x-ai/grok-3-mini",
      name: "xAI: Grok 3 Mini",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.3, output: 0.5, cache_read: 0.075, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 4_096
    },
    "x-ai/grok-3-mini-beta" => %Model{
      id: "x-ai/grok-3-mini-beta",
      name: "xAI: Grok 3 Mini Beta",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.3, output: 0.5, cache_read: 0.075, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 4_096
    },
    "x-ai/grok-4" => %Model{
      id: "x-ai/grok-4",
      name: "xAI: Grok 4",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{input: 3.0, output: 15.0, cache_read: 0.75, cache_write: 0.0},
      context_window: 256_000,
      max_tokens: 4_096
    },
    "x-ai/grok-4-fast" => %Model{
      id: "x-ai/grok-4-fast",
      name: "xAI: Grok 4 Fast",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.19999999999999998,
        output: 0.5,
        cache_read: 0.049999999999999996,
        cache_write: 0.0
      },
      context_window: 2_000_000,
      max_tokens: 30_000
    },
    "x-ai/grok-4.1-fast" => %Model{
      id: "x-ai/grok-4.1-fast",
      name: "xAI: Grok 4.1 Fast",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.19999999999999998,
        output: 0.5,
        cache_read: 0.049999999999999996,
        cache_write: 0.0
      },
      context_window: 2_000_000,
      max_tokens: 30_000
    },
    "x-ai/grok-code-fast-1" => %Model{
      id: "x-ai/grok-code-fast-1",
      name: "xAI: Grok Code Fast 1",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.19999999999999998,
        output: 1.5,
        cache_read: 0.02,
        cache_write: 0.0
      },
      context_window: 256_000,
      max_tokens: 10_000
    },
    "xiaomi/mimo-v2-flash" => %Model{
      id: "xiaomi/mimo-v2-flash",
      name: "Xiaomi: MiMo-V2-Flash",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.09, output: 0.29, cache_read: 0.045, cache_write: 0.0},
      context_window: 262_144,
      max_tokens: 65_536
    },
    "z-ai/glm-4-32b" => %Model{
      id: "z-ai/glm-4-32b",
      name: "Z.ai: GLM 4 32B ",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: false,
      input: [:text],
      cost: %ModelCost{
        input: 0.09999999999999999,
        output: 0.09999999999999999,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 128_000,
      max_tokens: 4_096
    },
    "z-ai/glm-4.5" => %Model{
      id: "z-ai/glm-4.5",
      name: "Z.ai: GLM 4.5",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.55, output: 2.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_000,
      max_tokens: 131_000
    },
    "z-ai/glm-4.5-air" => %Model{
      id: "z-ai/glm-4.5-air",
      name: "Z.ai: GLM 4.5 Air",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.13,
        output: 0.85,
        cache_read: 0.024999999999999998,
        cache_write: 0.0
      },
      context_window: 131_072,
      max_tokens: 98_304
    },
    "z-ai/glm-4.5-air:free" => %Model{
      id: "z-ai/glm-4.5-air:free",
      name: "Z.ai: GLM 4.5 Air (free)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.0, output: 0.0, cache_read: 0.0, cache_write: 0.0},
      context_window: 131_072,
      max_tokens: 96_000
    },
    "z-ai/glm-4.5v" => %Model{
      id: "z-ai/glm-4.5v",
      name: "Z.ai: GLM 4.5V",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.6,
        output: 1.7999999999999998,
        cache_read: 0.11,
        cache_write: 0.0
      },
      context_window: 65_536,
      max_tokens: 16_384
    },
    "z-ai/glm-4.6" => %Model{
      id: "z-ai/glm-4.6",
      name: "Z.ai: GLM 4.6",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.35, output: 1.71, cache_read: 0.0, cache_write: 0.0},
      context_window: 202_752,
      max_tokens: 131_072
    },
    "z-ai/glm-4.6:exacto" => %Model{
      id: "z-ai/glm-4.6:exacto",
      name: "Z.ai: GLM 4.6 (exacto)",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.44, output: 1.76, cache_read: 0.11, cache_write: 0.0},
      context_window: 204_800,
      max_tokens: 131_072
    },
    "z-ai/glm-4.6v" => %Model{
      id: "z-ai/glm-4.6v",
      name: "Z.ai: GLM 4.6V",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text, :image],
      cost: %ModelCost{
        input: 0.3,
        output: 0.8999999999999999,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 131_072,
      max_tokens: 131_072
    },
    "z-ai/glm-4.7" => %Model{
      id: "z-ai/glm-4.7",
      name: "Z.ai: GLM 4.7",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{input: 0.38, output: 1.7, cache_read: 0.19, cache_write: 0.0},
      context_window: 202_752,
      max_tokens: 65_535
    },
    "z-ai/glm-4.7-flash" => %Model{
      id: "z-ai/glm-4.7-flash",
      name: "Z.ai: GLM 4.7 Flash",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.06,
        output: 0.39999999999999997,
        cache_read: 0.0100000002,
        cache_write: 0.0
      },
      context_window: 202_752,
      max_tokens: 4_096
    },
    "z-ai/glm-5" => %Model{
      id: "z-ai/glm-5",
      name: "Z.ai: GLM 5",
      api: :openai_completions,
      provider: :openrouter,
      base_url: "https://openrouter.ai/api/v1",
      reasoning: true,
      input: [:text],
      cost: %ModelCost{
        input: 0.3,
        output: 2.5500000000000003,
        cache_read: 0.0,
        cache_write: 0.0
      },
      context_window: 204_800,
      max_tokens: 131_072
    }
  }

  @doc "Returns all OpenRouter model definitions as a map."
  @spec models() :: %{String.t() => Model.t()}
  def models, do: @models
end
